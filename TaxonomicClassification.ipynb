{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Taxonomic Classification</center>\n",
    "\n",
    "## Taxonomic Classification Methods for Metagenomic Data\n",
    "\n",
    "1. Mothur\n",
    "2. Dada2\n",
    "3. Qiime\n",
    "4. OneCodex Target Loci Analysis\n",
    "\n",
    "\n",
    "\n",
    "OTU PICKING STRATEGIES\n",
    "https://github.com/biocore/qiime/blob/master/doc/tutorials/otu_picking.rst\n",
    "\n",
    "QIIME PIPELINE\n",
    "1. OTU picking: open-reference OTU picking\n",
    "2. Identify chimeric sequences with Uchime (default)\n",
    "3. Taxonomy assignment with RDP (because good for medical)\n",
    "4. ALIGN SEQUENCES FOR PHYLOGENIC TREE using Pynast\n",
    "5. Infer phylogenetic tree using FastTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pipeline\n",
    "\n",
    "#### Server \n",
    "1. All analyses run on scg4.\n",
    "2. qlogin -l h_vmem=10G\n",
    "3. Most jobs submitted with qsub, not in interactive \n",
    "\n",
    "#### Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "#### Step 1: Download data using fastq-dump\n",
    "\n",
    "Downloaded 35 fastq files of 16S from SRA - each matches a one of 24 patients for which we have chart data\n",
    "\n",
    "```bash\n",
    "for foo in $(cat ~/bhatt/margaret/mgh/sure.txt); do\n",
    "\n",
    "fastq-dump $foo\n",
    "echo $foo\n",
    "\n",
    "done\n",
    "```\n",
    "\n",
    "SRR1196422\n",
    "SRR1196501\n",
    "SRR1196676\n",
    "SRR1196682\n",
    "SRR1196684\n",
    "SRR1196714\n",
    "SRR1196732\n",
    "SRR1196775\n",
    "SRR1196776\n",
    "SRR1196786\n",
    "SRR1196826\n",
    "SRR1196876\n",
    "SRR1196880\n",
    "SRR1196897\n",
    "SRR1196901\n",
    "SRR1196902\n",
    "SRR1196924\n",
    "SRR1196930\n",
    "SRR1201469\n",
    "SRR1201508\n",
    "SRR1201509\n",
    "SRR1201518\n",
    "SRR1201576\n",
    "SRR1201585\n",
    "SRR1196333\n",
    "SRR1196334\n",
    "SRR1196336\n",
    "SRR1196343\n",
    "SRR1196351\n",
    "SRR1196399\n",
    "SRR1196416\n",
    "SRR1196966\n",
    "SRR1196974\n",
    "SRR1201472\n",
    "SRR1201557\n",
    "\n",
    "#### Step 2: Run Fastqc on all samples\n",
    "\n",
    "Just ran it in interactive qlogin instead of qsub since so few samples\n",
    "\n",
    "```bash\n",
    "PROJECT_PATH=\"/srv/gsfs0/projects/bhatt/margaret/mgh\"\n",
    "DATA_PATH=\"/srv/gsfs0/projects/bhatt/margaret/mgh/raw\"\n",
    "module load fastqc/0.11.2\n",
    "fastqc --extract -t 10 --outdir=$PROJECT_PATH/fastqc/ $DATA_PATH/*fastq\n",
    "```\n",
    "\n",
    "#### Step 3: Check quality of samples\n",
    "Go into directory with fastqc results and check which ones failed. The summary.txt file in each directory created by FastQC for each sample has cat-able results\n",
    "```bash\n",
    "cat SRR*_fastqc/summary.txt | grep FAIL > failed_fastqc.txt\n",
    "\n",
    "# Number that failed \"Per base sequence quality\" test\n",
    "cat failed_fastqc.txt | grep quality | wc -l\n",
    "# in this run: 35/35\n",
    "\n",
    "# Number that failed \"Per sequence GC content\" test\n",
    "cat failed_fastqc.txt | grep GC\\ \\content | wc -l\n",
    "# in this run: 30/35\n",
    "\n",
    "# Number that failed \"Per base sequence content\" test\n",
    "cat failed_fastqc.txt | grep sequence\\ \\content | wc -l\n",
    "# in this run: 35/35\n",
    "\n",
    "# Number that failed \"Kmer Content\" test\n",
    "cat failed_fastqc.txt | grep Kmer\\ \\Content | wc -l\n",
    "# in this run: 30/35\n",
    "\n",
    "# Number that failed \"Sequence Duplication Levels\" test\n",
    "cat failed_fastqc.txt | grep Sequence\\ \\Duplication\\ \\Levels | wc -l\n",
    "# in this run: 35/35\n",
    "\n",
    "# Number that failed \"Overrepresented sequences\" test\n",
    "cat failed_fastqc.txt | grep Overrepresented\\ \\sequences | wc -l\n",
    "# in this run: 35/35\n",
    "\n",
    "```\n",
    "\n",
    "#### Step 4: Deduplication using super_deduper\n",
    "```bash\n",
    "cat ~/bhatt/margaret/mgh/raw/samples_mgh.txt | xargs -n 3 -I foo sh -c \"~/bhatt/moss/tools/qc/Super-Deduper/super_deduper -s 5 -l 90 -p ~/bhatt/margaret/mgh/dedup/foo -U foo.fastq\"\n",
    "```\n",
    "\n",
    "#### Step 5: Trim adapter sequences with trim_galore (trim and fastqc wrapper)\n",
    "cutadapt 1.7.1 with Python 2.7.6\n",
    "\n",
    "Determining trimming parameters\n",
    "```bash\n",
    "cat SRR*_fastqc/fastqc_data.txt | grep Per\\ \\base\\ \\sequence\\ \\quality -A 11\n",
    "```\n",
    "\n",
    "```bash\n",
    "trim_galore -q 20 --fastqc --length 250 -o $PROJECT_PATH/trim/trimmed_\"$foo\" -U $DATA_PATH/\"$foo\"_nodup_PE1.fastq\n",
    "```\n",
    "\n",
    "Get read length distribution for sample foo\n",
    "```bash\n",
    "cat \"$foo\".fastq | perl -ne '$s=<>;<>;<>;chomp($s);print length($s).\"\\n\";' >  \"$foo\".readslength.txt\n",
    "```\n",
    "\n",
    "How many sequences were removed because of the 250 bp (75% of original length of 350bp) length cutoff:\n",
    "```bash\n",
    "cat trimmed_SRR1*/*report.txt | grep Sequences\\ \\removed\n",
    "```\n",
    "\n",
    "#### Step 6: Reassess Sequence Quality after Trimming\n",
    "\n",
    "1. Adapter Sequence Removal: Used default Universal Illumina Adapter. PASS on all after removal\n",
    "2. Concatenated all FAIL tests into one file for easy grepping\n",
    "3. Common FAIL tests in trimmed+deduped reads\n",
    "4. Deduplication with Super-Deduper seems to have had little effect. 28/35 samples still have high duplication levels.\n",
    "5. Looking at top 5 overrepresented sequences: representation 2-13% of the sample\n",
    "6. For FAILED Kmer tests, anywhere from 5 to 830 counts of overrepresented KMER\n",
    "7. Up to 3182 count for sequences with GC content FAIL\n",
    "\n",
    "```bash\n",
    "# Number that failed \"Per base sequence quality\" test\n",
    "cat failed_fastqc.txt | grep quality | wc -l\n",
    "# in this run: 14/35\n",
    "\n",
    "# Number that failed \"Per sequence GC content\" test\n",
    "cat failed_fastqc.txt | grep GC\\ \\content | wc -l\n",
    "# in this run: 12/35\n",
    "\n",
    "# Number that failed \"Per base sequence content\" test\n",
    "cat failed_fastqc.txt | grep sequence\\ \\content | wc -l\n",
    "# in this run: 35/35\n",
    "\n",
    "# Number that failed \"Kmer Content\" test\n",
    "cat failed_fastqc.txt | grep Kmer\\ \\Content | wc -l\n",
    "# in this run: 28/35\n",
    "\n",
    "# Number that failed \"Sequence Duplication Levels\" test\n",
    "cat failed_fastqc.txt | grep Sequence\\ \\Duplication\\ \\Levels | wc -l\n",
    "# in this run: 28/35\n",
    "\n",
    "# Number that failed \"Overrepresented sequences\" test\n",
    "cat failed_fastqc.txt | grep Overrepresented\\ \\sequences | wc -l\n",
    "# in this run: 35/35\n",
    "\n",
    "cat *fastqc/*summary.txt |grep FAIL >fails.txt\n",
    "cat *fastqc/fastqc_data.txt | grep Overrepresented -A 2 |sort -k 3 -n\n",
    "cat *fastqc/fastqc_data.txt | grep Kmer -A 4 | sort -k 2 -n\n",
    "\n",
    "```\n",
    "\n",
    "## OTU binning and classification with QIIME\n",
    "\n",
    "[Tutorial for reference](http://nbviewer.jupyter.org/github/biocore/qiime/blob/1.9.1/examples/ipynb/illumina_overview_tutorial.ipynb)\n",
    "#### Step 1: Set up Qiime environment\n",
    "```bash\n",
    "# Install Anaconda http://conda.pydata.org/docs/install/quick.html#os-x-miniconda-install\n",
    "# Download installer and run bash script\n",
    "\n",
    "# Install Qiime http://qiime.org/install/install.html\n",
    "conda create -n qiime1 python=2.7 qiime matplotlib=1.4.3 mock nose -c bioconda\n",
    "\n",
    "# Check installation\n",
    "conda list\n",
    "conda update\n",
    "\n",
    "# To activate this environment, use:\n",
    "source activate qiime1\n",
    "\n",
    "# To deactivate this environment, use:\n",
    "source deactivate qiime1\n",
    "```\n",
    "#### Step 2: Convert fastq files to fasta \n",
    "\n",
    "```bash\n",
    "# Download libgtextutils (dependency of fastx_toolkit)\n",
    "curl -O https://github.com/agordon/libgtextutils/releases/download/0.7/libgtextutils-0.7.tar.gz\n",
    "gunzip libgtextutils-0.7.tar.gz\n",
    "tar xvf libgtextutils-0.7.tar\n",
    "cd libgtextutils-0.7\n",
    "./configure\n",
    "make\n",
    "sudo make install\n",
    "\n",
    "# Download fastx-toolkit\n",
    "curl -O https://github.com/agordon/fastx_toolkit/releases/download/0.0.14/fastx_toolkit-0.0.14.tar.bz2\n",
    "tar xvf fastx_toolkit-0.0.14.tar.bz2\n",
    "cd fastx_toolkit-0.0.14\n",
    "# Make sure pkg-utils is up to date, if not then \n",
    "# brew install pkg-config\n",
    "export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH\n",
    "./configure\n",
    "make\n",
    "sudo make install\n",
    "# fastx toolkit should now be installed\n",
    "\n",
    "# Run fastx tool fastq_to_fasta - done in bash\n",
    "fastq_to_fasta -i SRRXXXXX.fq -o SRRXXXXX.fa\n",
    "\n",
    "# Look at fasta files (after trim_galore and deduping, but before concatenation for Qiime)\n",
    "# In directory with fasta files, get number of seqs in each file:\n",
    "# grep -c \"^>\" * \n",
    "\n",
    "SRR1196422\t22366\n",
    "SRR1196501\t22989\n",
    "SRR1196676\t10205\n",
    "SRR1196682\t41048\n",
    "SRR1196684\t23049\n",
    "SRR1196714\t35192\n",
    "SRR1196732\t3078\n",
    "SRR1196775\t32083\n",
    "SRR1196776\t5356\n",
    "SRR1196786\t8378\n",
    "SRR1196826\t21424\n",
    "SRR1196876\t43310\n",
    "SRR1196880\t21040\n",
    "SRR1196897\t51981\n",
    "SRR1196901\t17216\n",
    "SRR1196902\t43941\n",
    "SRR1196924\t17290\n",
    "SRR1196930\t76677\n",
    "SRR1201469\t6345\n",
    "SRR1201508\t32424\n",
    "SRR1201509\t1714\n",
    "SRR1201518\t6323\n",
    "SRR1201576\t67603\n",
    "SRR1201585\t43558\n",
    "```\n",
    "\n",
    "#### Step 3: Label sequences by sample from which they originated and merge all samples into one file\n",
    "\n",
    "If barcodes are used, then this is naturally uneccessary, however, starting with samples that are individual fastq/fasta files, this is a solution for accetable input into qiime tools, such as core_diversity_analysis.py\n",
    "\n",
    "[See Google Qiime Forum for reference](https://groups.google.com/forum/#!topic/qiime-forum/XDQnB_QPfHI)\n",
    "\n",
    "```bash\n",
    "# Create map text file mapping.txt\n",
    "\n",
    "    \n",
    "# add_qiime_labels.py -m mapping.txt -i fasta/ -c InputFileColName -o fastaForQiime/\n",
    "\n",
    "add_qiime_labels.py -m mapping.txt -i fasta/ -c InputFileName -o fastaForQiime/\n",
    "\n",
    "# Now have combined_seqs.fna in fastaForQiime/\n",
    "\n",
    "# Count number of sequences in combined file\n",
    "count_seqs.py -i fastaForQiime/combined_seqs.fna\n",
    "#654590  : fastaForQiime/combined_seqs.fna (Sequence lengths (mean +/- std): 323.4642 +/- 43.4627)\n",
    "#654590  : Total\n",
    "```\n",
    "\n",
    "#### Step 4: Pick open reference OTUs\n",
    "```bash\n",
    "# Pick open reference OTUs (takes many minutes...maybe an hour)\n",
    "pick_open_reference_otus.py -o otus/ -i fastaForQiime/combined_seqs.fna -p ../uc_fast_params.txt\n",
    "\n",
    "# Summaryze BIOM table\n",
    "\n",
    "biom summarize-table -i otus/otu_table_mc2_w_tax_no_pynast_failures.biom\n",
    "#Num samples: 24\n",
    "#Num observations: 219\n",
    "#Total count: 2310\n",
    "#Table density (fraction of non-zero values): 0.086\n",
    "\n",
    "#Counts/sample summary:\n",
    " #Min: 1.0\n",
    " #Max: 721.0\n",
    " #Median: 58.000\n",
    " #Mean: 96.250\n",
    " #Std. dev.: 146.039\n",
    " #Sample Metadata Categories: None provided\n",
    " #Observation Metadata Categories: taxonomy\n",
    "\n",
    "#Counts/sample detail:\n",
    "#SRR1196924: 1.0\n",
    "#SRR1201509: 2.0\n",
    "#SRR1201469: 3.0\n",
    "#SRR1196732: 13.0\n",
    "#SRR1196786: 13.0\n",
    "#SRR1196501: 14.0\n",
    "#SRR1196897: 22.0\n",
    "#SRR1196422: 25.0\n",
    "#SRR1201518: 27.0\n",
    "#SRR1201508: 32.0\n",
    "#SRR1196684: 41.0\n",
    "#SRR1196776: 58.0\n",
    "#SRR1196880: 58.0\n",
    "#SRR1201576: 60.0\n",
    "#SRR1196901: 66.0\n",
    "#SRR1196775: 69.0\n",
    "#SRR1196826: 91.0\n",
    "#SRR1196876: 100.0\n",
    "#SRR1196676: 110.0\n",
    "#SRR1201585: 152.0\n",
    "#SRR1196902: 166.0\n",
    "#SRR1196930: 223.0\n",
    "#SRR1196714: 243.0\n",
    "#SRR1196682: 721.0\n",
    "\n",
    "```\n",
    "#### Step 5: Diversity analysis\n",
    "Probably shouldn't do this because of low counts in biom table\n",
    "```bash\n",
    "core_diversity_analyses.py -o cdout/ -i otus/otu_table_mc2_w_tax_no_pynast_failures.biom -m files/mapping.txt -t otus/rep_set.tre -e 50\n",
    "# All classifications UNKNOWN. Because of low count in Step 4. But why?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Dada2\n",
    "\n",
    "[See tutorial here](http://benjjneb.github.io/dada2/tutorial.html)\n",
    "\n",
    "```bash\n",
    "# Install\n",
    "source(\"https://bioconductor.org/biocLite.R\")\n",
    "biocLite(\"dada2\")\n",
    "library(dada2); packageVersion(\"dada2\")\n",
    "library(ShortRead); packageVersion(\"ShortRead\")\n",
    "library(ggplot2); packageVersion(\"ggplot2\")\n",
    "\n",
    "> path<-\"../raw/\"\n",
    "> fns<-list.files(path)\n",
    "> fns\n",
    " [1] \"SRR1196422.fastq\" \"SRR1196501.fastq\"\n",
    " [3] \"SRR1196676.fastq\" \"SRR1196682.fastq\"\n",
    " [5] \"SRR1196684.fastq\" \"SRR1196714.fastq\"\n",
    " [7] \"SRR1196732.fastq\" \"SRR1196775.fastq\"\n",
    " [9] \"SRR1196776.fastq\" \"SRR1196786.fastq\"\n",
    "[11] \"SRR1196826.fastq\" \"SRR1196876.fastq\"\n",
    "[13] \"SRR1196880.fastq\" \"SRR1196897.fastq\"\n",
    "[15] \"SRR1196901.fastq\" \"SRR1196902.fastq\"\n",
    "[17] \"SRR1196924.fastq\" \"SRR1196930.fastq\"\n",
    "[19] \"SRR1201469.fastq\" \"SRR1201508.fastq\"\n",
    "[21] \"SRR1201509.fastq\" \"SRR1201518.fastq\"\n",
    "[23] \"SRR1201576.fastq\" \"SRR1201585.fastq\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
